{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def convert_tif_to_png(input_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith(\".tif\"):\n",
    "            tif_path = os.path.join(input_dir, filename)\n",
    "            output_path = os.path.join(output_dir, os.path.splitext(filename)[0] + \".png\")\n",
    "            with Image.open(tif_path) as tif_image:\n",
    "                tif_image.save(output_path, \"PNG\")\n",
    "\n",
    "# Example usage\n",
    "input_dir = \"4cam_auth\"\n",
    "output_dir = \"4cam_original\"\n",
    "convert_tif_to_png(input_dir, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def convert_tif_to_png(input_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith(\".tif\"):\n",
    "            tif_path = os.path.join(input_dir, filename)\n",
    "            output_path = os.path.join(output_dir, os.path.splitext(filename)[0] + \".png\")\n",
    "            with Image.open(tif_path) as tif_image:\n",
    "                tif_image.save(output_path, \"PNG\")\n",
    "\n",
    "# Example usage\n",
    "input_dir = \"4cam_splc\"\n",
    "output_dir = \"4cam_spliced\"\n",
    "convert_tif_to_png(input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preparation completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Define the paths to your original and spliced image folders\n",
    "original_images_folder = '4cam_original'\n",
    "spliced_images_folder = '4cam_spliced'\n",
    "\n",
    "# Define the output paths for the training and testing sets\n",
    "training_folder = 'training_set'\n",
    "testing_folder = 'testing_set'\n",
    "\n",
    "# Set the ratio of training to testing images (e.g., 80:20)\n",
    "training_ratio = 0.8\n",
    "\n",
    "# Create the output directories if they don't exist\n",
    "os.makedirs(os.path.join(training_folder, 'original'), exist_ok=True)\n",
    "os.makedirs(os.path.join(training_folder, 'spliced'), exist_ok=True)\n",
    "os.makedirs(os.path.join(testing_folder, 'original'), exist_ok=True)\n",
    "os.makedirs(os.path.join(testing_folder, 'spliced'), exist_ok=True)\n",
    "\n",
    "# Collect the list of original image files\n",
    "original_files = os.listdir(original_images_folder)\n",
    "# Collect the list of spliced image files\n",
    "spliced_files = os.listdir(spliced_images_folder)\n",
    "\n",
    "# Shuffle the file lists to ensure randomness\n",
    "random.shuffle(original_files)\n",
    "random.shuffle(spliced_files)\n",
    "\n",
    "# Determine the number of images for training and testing based on the ratio\n",
    "num_training_original = int(len(original_files) * training_ratio)\n",
    "num_testing_original = len(original_files) - num_training_original\n",
    "num_training_spliced = int(len(spliced_files) * training_ratio)\n",
    "num_testing_spliced = len(spliced_files) - num_training_spliced\n",
    "\n",
    "# Move original images to the training set\n",
    "for file in original_files[:num_training_original]:\n",
    "    src = os.path.join(original_images_folder, file)\n",
    "    dst = os.path.join(training_folder, 'original', file)\n",
    "    shutil.copy(src, dst)\n",
    "\n",
    "# Move original images to the testing set\n",
    "for file in original_files[num_training_original:]:\n",
    "    src = os.path.join(original_images_folder, file)\n",
    "    dst = os.path.join(testing_folder, 'original', file)\n",
    "    shutil.copy(src, dst)\n",
    "\n",
    "# Move spliced images to the training set\n",
    "for file in spliced_files[:num_training_spliced]:\n",
    "    src = os.path.join(spliced_images_folder, file)\n",
    "    dst = os.path.join(training_folder, 'spliced', file)\n",
    "    shutil.copy(src, dst)\n",
    "\n",
    "# Move spliced images to the testing set\n",
    "for file in spliced_files[num_training_spliced:]:\n",
    "    src = os.path.join(spliced_images_folder, file)\n",
    "    dst = os.path.join(testing_folder, 'spliced', file)\n",
    "    shutil.copy(src, dst)\n",
    "\n",
    "print(\"Dataset preparation completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 290 images belonging to 2 classes.\n",
      "Found 73 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 52s 5s/step - loss: 3.3640 - accuracy: 0.4961 - val_loss: 0.9498 - val_accuracy: 0.7188\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 40s 4s/step - loss: 0.9695 - accuracy: 0.5853 - val_loss: 0.9732 - val_accuracy: 0.6875\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.9616 - accuracy: 0.6589 - val_loss: 0.9353 - val_accuracy: 0.6719\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.9110 - accuracy: 0.6434 - val_loss: 0.9825 - val_accuracy: 0.4375\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.8841 - accuracy: 0.5698 - val_loss: 0.8273 - val_accuracy: 0.6562\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.9059 - accuracy: 0.6240 - val_loss: 0.8043 - val_accuracy: 0.5781\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.8304 - accuracy: 0.6240 - val_loss: 0.8019 - val_accuracy: 0.7969\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 39s 4s/step - loss: 0.8258 - accuracy: 0.7014 - val_loss: 0.7769 - val_accuracy: 0.7656\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 34s 4s/step - loss: 0.7963 - accuracy: 0.7054 - val_loss: 0.7252 - val_accuracy: 0.6719\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 34s 4s/step - loss: 0.7611 - accuracy: 0.7481 - val_loss: 0.6587 - val_accuracy: 0.7812\n",
      "3/3 [==============================] - 4s 895ms/step - loss: 0.6616 - accuracy: 0.7808\n",
      "Test Loss: 0.6616281867027283\n",
      "Test Accuracy: 0.7808219194412231\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Data augmentation and preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'training_set',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'testing_set',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // 32,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // 32,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 290 images belonging to 2 classes.\n",
      "Found 73 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 40s 5s/step - loss: 3.2739 - accuracy: 0.5736 - val_loss: 0.9032 - val_accuracy: 0.5469\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.9870 - accuracy: 0.5310 - val_loss: 1.0114 - val_accuracy: 0.5469\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 44s 4s/step - loss: 1.0244 - accuracy: 0.6279 - val_loss: 0.9961 - val_accuracy: 0.7188\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 37s 4s/step - loss: 0.9937 - accuracy: 0.7093 - val_loss: 0.9553 - val_accuracy: 0.6250\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 35s 4s/step - loss: 1.0207 - accuracy: 0.5543 - val_loss: 0.9841 - val_accuracy: 0.6406\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.9738 - accuracy: 0.6202 - val_loss: 0.9326 - val_accuracy: 0.4844\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.9313 - accuracy: 0.7016 - val_loss: 0.8767 - val_accuracy: 0.7656\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.9044 - accuracy: 0.7093 - val_loss: 0.8366 - val_accuracy: 0.6562\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.8662 - accuracy: 0.7326 - val_loss: 0.7773 - val_accuracy: 0.7344\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 36s 4s/step - loss: 0.8500 - accuracy: 0.6840 - val_loss: 0.7527 - val_accuracy: 0.7969\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001FABC6527A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 4s 959ms/step\n",
      "3/3 [==============================] - 4s 951ms/step - loss: 0.7476 - accuracy: 0.7945\n",
      "Test Loss: 0.7476335763931274\n",
      "Test Accuracy: 0.7945205569267273\n",
      "Precision: 0.4888888888888889\n",
      "Recall: 0.6111111111111112\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Data augmentation and preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'training_set',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'testing_set',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // 32,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // 32,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "predictions = model.predict(test_generator)\n",
    "y_pred = np.where(predictions > 0.5, 1, 0)\n",
    "\n",
    "precision = precision_score(test_generator.classes, y_pred)\n",
    "recall = recall_score(test_generator.classes, y_pred)\n",
    "\n",
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGzCAYAAADT4Tb9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA1nUlEQVR4nO3df3zP9f7/8ft7Y+9tZvNjP5iWCQf5WcOaHzlqWUiUiklGUjl+xPSJFUbOaSpJ5Vccv0uWlOOYiEU/cBKao9IyPyKnDWGbOTa21/ePvt6nd5uy2by3p9v1cnlf6v18PZ+v1+P1fr33ft+9fr1tlmVZAgAAMISbqwsAAAAoTYQbAABgFMINAAAwCuEGAAAYhXADAACMQrgBAABGIdwAAACjEG4AAIBRCDcAAMAohBsATmw2myZNmlTscYcPH5bNZtPixYtLvaarsWzZMjVu3FiVK1dWtWrVXF0OgGuAcAOUQ4sXL5bNZpPNZtPnn39eaLplWQoJCZHNZtM999zjggpLbsuWLY51s9lsqly5sm666SYNGDBABw8eLNVlfffddxo4cKDq16+v+fPna968eaU6fwDlUyVXFwDg8jw9PbV8+XJ16NDBqf2TTz7Rjz/+KLvd7qLKrt7IkSPVpk0bXbhwQbt379a8efOUlJSkvXv3Kjg4uFSWsWXLFhUUFOi1115TgwYNSmWeAMo/9twA5Vi3bt20cuVKXbx40al9+fLlCgsLU61atVxU2dXr2LGj+vfvr0GDBumNN97QtGnTdOrUKS1ZsuSq552TkyNJOn78uCSV6uGoc+fOldq8AJQNwg1QjkVHR+vnn3/Wxo0bHW15eXl677331K9fvyLH5OTkaMyYMQoJCZHdblejRo00bdo0WZbl1C83N1ejR49WQECAqlatqnvvvVc//vhjkfM8duyYHn30UQUFBclut6tp06ZauHBh6a2opDvuuEOSdOjQIUfbhx9+qI4dO6pKlSqqWrWqunfvrm+++cZp3MCBA+Xj46MDBw6oW7duqlq1qh5++GGFhoYqPj5ekhQQEFDoXKLZs2eradOmstvtCg4O1rBhw3TmzBmnef/5z39Ws2bNtGvXLt1+++3y9vbWs88+6zi/aNq0aZo1a5ZuuukmeXt7q0uXLjp69Kgsy9KUKVN0ww03yMvLSz179tSpU6ec5v2Pf/xD3bt3V3BwsOx2u+rXr68pU6YoPz+/yBq+/fZbde7cWd7e3qpTp45eeumlQq/h+fPnNWnSJP3pT3+Sp6enateurfvvv18HDhxw9CkoKNCMGTPUtGlTeXp6KigoSE888YROnz595RsLKOc4LAWUY6GhoYqIiNA777yjrl27SvrlCz8zM1N9+/bV66+/7tTfsizde++92rx5swYPHqxWrVppw4YN+r//+z8dO3ZMr776qqPvY489prfeekv9+vVTu3bt9PHHH6t79+6FasjIyNBtt90mm82m4cOHKyAgQB9++KEGDx6srKwsjRo1qlTW9dIXcM2aNSX9ciJwTEyMoqKi9OKLL+rcuXOaM2eOOnTooK+++kqhoaGOsRcvXlRUVJQ6dOigadOmydvbWwMHDtTSpUv1wQcfaM6cOfLx8VGLFi0kSZMmTdLkyZMVGRmpoUOHKjU1VXPmzNGXX36prVu3qnLlyo55//zzz+ratav69u2r/v37KygoyDHt7bffVl5enkaMGKFTp07ppZde0kMPPaQ77rhDW7Zs0dixY5WWlqY33nhDTz/9tFMgXLx4sXx8fBQbGysfHx99/PHHmjhxorKysvTyyy87vTanT5/W3Xffrfvvv18PPfSQ3nvvPY0dO1bNmzd3vC/y8/N1zz33KDk5WX379tVTTz2l7Oxsbdy4UV9//bXq168vSXriiSe0ePFiDRo0SCNHjtShQ4c0c+ZMffXVV4XWHaiwLADlzqJFiyxJ1pdffmnNnDnTqlq1qnXu3DnLsizrwQcftDp37mxZlmXVrVvX6t69u2Pc6tWrLUnWX//6V6f5PfDAA5bNZrPS0tIsy7KslJQUS5L1l7/8xalfv379LElWfHy8o23w4MFW7dq1rZMnTzr17du3r+Xn5+eo69ChQ5Yka9GiRb+7bps3b7YkWQsXLrROnDhh/ec//7GSkpKs0NBQy2azWV9++aWVnZ1tVatWzRoyZIjT2PT0dMvPz8+pPSYmxpJkjRs3rtCy4uPjLUnWiRMnHG3Hjx+3PDw8rC5dulj5+fmO9pkzZzrquqRTp06WJGvu3LlO8720rgEBAdaZM2cc7XFxcZYkq2XLltaFCxcc7dHR0ZaHh4d1/vx5R9ul1+3XnnjiCcvb29up36Uali5d6mjLzc21atWqZfXu3dvRtnDhQkuSNX369ELzLSgosCzLsj777DNLkvX22287TV+/fn2R7UBFxWEpoJx76KGH9N///ldr165Vdna21q5de9lDUuvWrZO7u7tGjhzp1D5mzBhZlqUPP/zQ0U9SoX6/3QtjWZZWrVqlHj16yLIsnTx50vGIiopSZmamdu/eXaL1evTRRxUQEKDg4GB1795dOTk5WrJkiVq3bq2NGzfqzJkzio6Odlqmu7u7wsPDtXnz5kLzGzp06BUtd9OmTcrLy9OoUaPk5va/j8AhQ4bI19dXSUlJTv3tdrsGDRpU5LwefPBB+fn5OZ6Hh4dLkvr3769KlSo5tefl5enYsWOONi8vL8f/Z2dn6+TJk+rYsaPOnTun7777zmk5Pj4+6t+/v+O5h4eH2rZt63R12apVq+Tv768RI0YUqtNms0mSVq5cKT8/P911111Or2tYWJh8fHyKfF2BiojDUkA5FxAQoMjISC1fvlznzp1Tfn6+HnjggSL7/vDDDwoODlbVqlWd2ps0aeKYfum/bm5ujkMVlzRq1Mjp+YkTJ3TmzBnNmzfvspdRXzppt7gmTpyojh07yt3dXf7+/mrSpIkjEOzfv1/S/87D+S1fX1+n55UqVdINN9xwRcu99Br8dl09PDx00003OaZfUqdOHXl4eBQ5rxtvvNHp+aWgExISUmT7r89r+eabbzR+/Hh9/PHHysrKcuqfmZnp9PyGG25wBJRLqlevrn//+9+O5wcOHFCjRo2cQtVv7d+/X5mZmQoMDCxyekm3JVDeEG6ACqBfv34aMmSI0tPT1bVr12t2M7qCggJJv+yJiImJKbLPpfNYiqt58+aKjIz83eUuW7asyCvCfvsFbrfbnfbClKZf72H5LXd392K1W///pO4zZ86oU6dO8vX11fPPP6/69evL09NTu3fv1tixYx3rf6Xzu1IFBQUKDAzU22+/XeT0gICAYs0PKK8IN0AFcN999+mJJ57Qv/71LyUmJl62X926dbVp0yZlZ2c77b25dJijbt26jv8WFBQ4/rV/SWpqqtP8Ll1JlZ+ff9kgUhYu7VEKDAws9eVeeg1SU1N10003Odrz8vJ06NCha7KeW7Zs0c8//6z3339ft99+u6P911eKFVf9+vX1xRdf6MKFC5c9Kbh+/fratGmT2rdv/7uhDajoOOcGqAB8fHw0Z84cTZo0ST169Lhsv27duik/P18zZ850an/11Vdls9kcV9Zc+u9vr7aaMWOG03N3d3f17t1bq1at0tdff11oeSdOnCjJ6vyhqKgo+fr66oUXXtCFCxdKdbmRkZHy8PDQ66+/7rTnY8GCBcrMzCzyirHSdmlPzK+Xn5eXp9mzZ5d4nr1799bJkycLbftfL+ehhx5Sfn6+pkyZUqjPxYsXC10KD1RU7LkBKojLHRb6tR49eqhz58567rnndPjwYbVs2VIfffSR/vGPf2jUqFGOPSKtWrVSdHS0Zs+erczMTLVr107JyclKS0srNM+pU6dq8+bNCg8P15AhQ3TzzTfr1KlT2r17tzZt2lTo/i2lwdfXV3PmzNEjjzyiW2+9VX379lVAQICOHDmipKQktW/fvsgv8SsREBCguLg4TZ48WXfffbfuvfdepaamavbs2WrTpo3TibtlpV27dqpevbpiYmI0cuRI2Ww2LVu2rNiHmX5twIABWrp0qWJjY7Vjxw517NhROTk52rRpk/7yl7+oZ8+e6tSpk5544gklJCQoJSVFXbp0UeXKlbV//36tXLlSr7322mXP5wIqEsINYBA3NzetWbNGEydOVGJiohYtWqTQ0FC9/PLLGjNmjFPfhQsXKiAgQG+//bZWr16tO+64Q0lJSYVOhg0KCtKOHTv0/PPP6/3339fs2bNVs2ZNNW3aVC+++GKZrUu/fv0UHBysqVOn6uWXX1Zubq7q1Kmjjh07XvbqpSs1adIkBQQEaObMmRo9erRq1Kihxx9/XC+88MI1uc9LzZo1tXbtWo0ZM0bjx49X9erV1b9/f915552Kiooq0Tzd3d21bt06/e1vf9Py5cu1atUq1axZUx06dFDz5s0d/ebOnauwsDC9+eabevbZZ1WpUiWFhoaqf//+at++fWmtIuBSNutq/qkAAABQznDODQAAMArhBgAAGIVwAwAAjOLScPPpp5+qR48eCg4Ols1m0+rVq/9wzJYtW3TrrbfKbrerQYMGWrx4cZnXCQAAKg6XhpucnBy1bNlSs2bNuqL+hw4dUvfu3dW5c2elpKRo1KhReuyxx7Rhw4YyrhQAAFQU5eZqKZvNpg8++EC9evW6bJ+xY8cqKSnJ6WZiffv21ZkzZ7R+/fprUCUAACjvKtR9brZv317o1uhRUVGFfsn413Jzc5Wbm+t4XlBQoFOnTqlmzZqFfogOAACUT5ZlKTs7W8HBwX/4W3IVKtykp6crKCjIqS0oKEhZWVn673//W+RvpSQkJGjy5MnXqkQAAFCGjh49qhtuuOF3+1SocFMScXFxio2NdTzPzMzUjTfeqKNHj8rX19eFlQEAgCuVlZWlkJAQpx8FvpwKFW5q1aqljIwMp7aMjAz5+vpe9hdu7Xa77HZ7oXZfX1/CDQAAFcyVnFJSoe5zExERoeTkZKe2jRs3KiIiwkUVAQCA8sal4ebs2bNKSUlRSkqKpF8u9U5JSdGRI0ck/XJIacCAAY7+Tz75pA4ePKhnnnlG3333nWbPnq13331Xo0ePdkX5AACgHHJpuNm5c6duueUW3XLLLZKk2NhY3XLLLZo4caIk6aeffnIEHUmqV6+ekpKStHHjRrVs2VKvvPKK/v73v5f4V3QBAIB5ys19bq6VrKws+fn5KTMzk3NuAACoIIrz/V2hzrkBAAD4I4QbAABgFMINAAAwCuEGAAAYhXADAACMQrgBAABGIdwAAACjEG4AAIBRCDcAAMAohBsAAGAUwg0AADAK4QYAABiFcAMAAIxCuAEAAEYh3AAAAKMQbgAAgFEINwAAwCiEGwAAYBTCDQAAMArhBgAAGIVwAwAAjEK4AQAARiHcAAAAoxBuAACAUQg3AADAKIQbAABgFMINAAAwCuEGAAAYhXADAACMQrgBAABGIdwAAACjEG4AAIBRCDcAAMAohBsAAGAUwg0AADAK4QYAABiFcAMAAIxCuAEAAEYh3AAAAKMQbgAAgFEINwAAwCiEGwAAYBTCDQAAMArhBgAAGIVwAwAAjEK4AQAARiHcAAAAoxBuAACAUQg3AADAKIQbAABgFMINAAAwCuEGAAAYhXADAACMQrgBAABGIdwAAACjEG4AAIBRCDcAAMAohBsAAGAUwg0AADAK4QYAABiFcAMAAIxCuAEAAEYh3AAAAKO4PNzMmjVLoaGh8vT0VHh4uHbs2PG7/WfMmKFGjRrJy8tLISEhGj16tM6fP3+NqgUAAOWdS8NNYmKiYmNjFR8fr927d6tly5aKiorS8ePHi+y/fPlyjRs3TvHx8dq3b58WLFigxMREPfvss9e4cgAAUF65NNxMnz5dQ4YM0aBBg3TzzTdr7ty58vb21sKFC4vsv23bNrVv3179+vVTaGiounTpoujo6D/c2wMAAK4fLgs3eXl52rVrlyIjI/9XjJubIiMjtX379iLHtGvXTrt27XKEmYMHD2rdunXq1q3bZZeTm5urrKwspwcAADBXJVct+OTJk8rPz1dQUJBTe1BQkL777rsix/Tr108nT55Uhw4dZFmWLl68qCeffPJ3D0slJCRo8uTJpVo7AAAov1x+QnFxbNmyRS+88IJmz56t3bt36/3331dSUpKmTJly2TFxcXHKzMx0PI4ePXoNKwYAANeay/bc+Pv7y93dXRkZGU7tGRkZqlWrVpFjJkyYoEceeUSPPfaYJKl58+bKycnR448/rueee05uboWzmt1ul91uL/0VwHXFZnN1Bdcvy3J1BQAqGpftufHw8FBYWJiSk5MdbQUFBUpOTlZERESRY86dO1cowLi7u0uSLD4BAQCAXLjnRpJiY2MVExOj1q1bq23btpoxY4ZycnI0aNAgSdKAAQNUp04dJSQkSJJ69Oih6dOn65ZbblF4eLjS0tI0YcIE9ejRwxFyAADA9c2l4aZPnz46ceKEJk6cqPT0dLVq1Urr1693nGR85MgRpz0148ePl81m0/jx43Xs2DEFBASoR48e+tvf/uaqVQAAAOWMzbrOjudkZWXJz89PmZmZ8vX1dXU5qCA458Z1rq9PKACXU5zv7wp1tRQAAMAfIdwAAACjEG4AAIBRCDcAAMAohBsAAGAUwg0AADAK4QYAABiFcAMAAIxCuAEAAEYh3AAAAKMQbgAAgFEINwAAwCgu/VVwI/ELi67DLywCAMSeGwAAYBjCDQAAMArhBgAAGIVwAwAAjEK4AQAARiHcAAAAoxBuAACAUQg3AADAKIQbAABgFMINAAAwCuEGAAAYhXADAACMQrgBAABGIdwAAACjEG4AAIBRCDcAAMAohBsAAGAUwg0AADAK4QYAABiFcAMAAIxCuAEAAEYh3AAAAKMQbgAAgFEINwAAwCiEGwAAYBTCDQAAMArhBgAAGIVwAwAAjEK4AQAARiHcAAAAoxBuAACAUQg3AADAKIQbAABgFMINAAAwCuEGAAAYhXADAACMQrgBAABGIdwAAACjEG4AAIBRCDcAAMAohBsAAGAUwg0AADAK4QYAABiFcAMAAIxCuAEAAEYh3AAAAKMQbgAAgFEINwAAwCiEGwAAYJRKri4AAIAysdzm6gquX/0sly7e5XtuZs2apdDQUHl6eio8PFw7duz43f5nzpzRsGHDVLt2bdntdv3pT3/SunXrrlG1AACgvHPpnpvExETFxsZq7ty5Cg8P14wZMxQVFaXU1FQFBgYW6p+Xl6e77rpLgYGBeu+991SnTh398MMPqlat2rUvHgAAlEsuDTfTp0/XkCFDNGjQIEnS3LlzlZSUpIULF2rcuHGF+i9cuFCnTp3Stm3bVLlyZUlSaGjotSwZAACUcy47LJWXl6ddu3YpMjLyf8W4uSkyMlLbt28vcsyaNWsUERGhYcOGKSgoSM2aNdMLL7yg/Pz8yy4nNzdXWVlZTg8AAGAul4WbkydPKj8/X0FBQU7tQUFBSk9PL3LMwYMH9d577yk/P1/r1q3ThAkT9Morr+ivf/3rZZeTkJAgPz8/xyMkJKRU1wMAAJQvLj+huDgKCgoUGBioefPmKSwsTH369NFzzz2nuXPnXnZMXFycMjMzHY+jR49ew4oBAMC15rJzbvz9/eXu7q6MjAyn9oyMDNWqVavIMbVr11blypXl7u7uaGvSpInS09OVl5cnDw+PQmPsdrvsdnvpFg8AAMotl+258fDwUFhYmJKTkx1tBQUFSk5OVkRERJFj2rdvr7S0NBUUFDjavv/+e9WuXbvIYAMAAK4/Lj0sFRsbq/nz52vJkiXat2+fhg4dqpycHMfVUwMGDFBcXJyj/9ChQ3Xq1Ck99dRT+v7775WUlKQXXnhBw4YNc9UqAACAcsall4L36dNHJ06c0MSJE5Wenq5WrVpp/fr1jpOMjxw5Ije3/+WvkJAQbdiwQaNHj1aLFi1Up04dPfXUUxo7dqyrVgEAAJQzNsuyXHuP5GssKytLfn5+yszMlK+vb+kvwMbtvl2mDN/KbFbXub4+oVCq+PkF1ymDn18ozvd3hbpaCgAA4I8QbgAAgFEINwAAwCiEGwAAYBTCDQAAMArhBgAAGIVwAwAAjEK4AQAARiHcAAAAoxBuAACAUQg3AADAKIQbAABgFMINAAAwylWFm7y8PKWmpurixYulVQ8AAMBVKVG4OXfunAYPHixvb281bdpUR44ckSSNGDFCU6dOLdUCAQAAiqNE4SYuLk579uzRli1b5Onp6WiPjIxUYmJiqRUHAABQXJVKMmj16tVKTEzUbbfdJpvN5mhv2rSpDhw4UGrFAQAAFFeJ9tycOHFCgYGBhdpzcnKcwg4AAMC1VqJw07p1ayUlJTmeXwo0f//73xUREVE6lQEAAJRAiQ5LvfDCC+ratau+/fZbXbx4Ua+99pq+/fZbbdu2TZ988klp1wgAAHDFSrTnpkOHDtqzZ48uXryo5s2b66OPPlJgYKC2b9+usLCw0q4RAADgihV7z82FCxf0xBNPaMKECZo/f35Z1AQAAFBixd5zU7lyZa1ataosagEAALhqJTos1atXL61evbqUSwEAALh6JTqhuGHDhnr++ee1detWhYWFqUqVKk7TR44cWSrFAQAAFJfNsiyruIPq1at3+RnabDp48OBVFVWWsrKy5Ofnp8zMTPn6+pb+ArjPj+sU/618xdisrlOGmxWmW84frsv0K/0/3OJ8f5doz82hQ4dKVBgAAEBZu6pfBZcky7JUgp0/AAAAZaLE4Wbp0qVq3ry5vLy85OXlpRYtWmjZsmWlWRsAAECxleiw1PTp0zVhwgQNHz5c7du3lyR9/vnnevLJJ3Xy5EmNHj26VIsEAAC4UiUKN2+88YbmzJmjAQMGONruvfdeNW3aVJMmTSLcAAAAlynRYamffvpJ7dq1K9Terl07/fTTT1ddFAAAQEmVKNw0aNBA7777bqH2xMRENWzY8KqLAgAAKKkSHZaaPHmy+vTpo08//dRxzs3WrVuVnJxcZOgBAAC4VkoUbnr37q0vvvhCr776quNnGJo0aaIdO3bolltuKc36AKBM2SZzozdXseK5jQjKRonCjSSFhYXprbfeKs1aAAAArlqJzrlZt26dNmzYUKh9w4YN+vDDD6+6KAAAgJIqUbgZN26c8vPzC7VblqVx48ZddVEAAAAlVaJws3//ft18882F2hs3bqy0tLSrLgoAAKCkShRu/Pz8ivzl77S0NFWpUuWqiwIAACipEoWbnj17atSoUTpw4ICjLS0tTWPGjNG9995basUBAAAUV4nCzUsvvaQqVaqocePGqlevnurVq6fGjRurZs2amjZtWmnXCAAAcMVKdCm4n5+ftm3bpo0bN2rPnj3y8vJSy5Yt1bFjx9KuDwAAoFiKtedm+/btWrt2rSTJZrOpS5cuCgwM1LRp09S7d289/vjjys3NLZNCAQAArkSxws3zzz+vb775xvF87969GjJkiO666y6NGzdO//znP5WQkFDqRQIAAFypYoWblJQU3XnnnY7nK1asUNu2bTV//nzFxsbq9ddf57elAACASxUr3Jw+fVpBQUGO55988om6du3qeN6mTRsdPXq09KoDAAAopmKFm6CgIB06dEiSlJeXp927d+u2225zTM/OzlblypVLt0IAAIBiKFa46datm8aNG6fPPvtMcXFx8vb2drpC6t///rfq169f6kUCAABcqWJdCj5lyhTdf//96tSpk3x8fLRkyRJ5eHg4pi9cuFBdunQp9SIBAACuVLHCjb+/vz799FNlZmbKx8dH7u7uTtNXrlwpHx+fUi0QAACgOEp8E7+i1KhR46qKAQAAuFol+vkFAACA8opwAwAAjEK4AQAARiHcAAAAoxBuAACAUQg3AADAKIQbAABgFMINAAAwCuEGAAAYhXADAACMQrgBAABGKRfhZtasWQoNDZWnp6fCw8O1Y8eOKxq3YsUK2Ww29erVq2wLBAAAFYbLw01iYqJiY2MVHx+v3bt3q2XLloqKitLx48d/d9zhw4f19NNPq2PHjteoUgAAUBG4PNxMnz5dQ4YM0aBBg3TzzTdr7ty58vb21sKFCy87Jj8/Xw8//LAmT56sm2666Xfnn5ubq6ysLKcHAAAwl0vDTV5ennbt2qXIyEhHm5ubmyIjI7V9+/bLjnv++ecVGBiowYMH/+EyEhIS5Ofn53iEhISUSu0AAKB8cmm4OXnypPLz8xUUFOTUHhQUpPT09CLHfP7551qwYIHmz59/RcuIi4tTZmam43H06NGrrhsAAJRflVxdQHFkZ2frkUce0fz58+Xv739FY+x2u+x2exlXBgAAyguXhht/f3+5u7srIyPDqT0jI0O1atUq1P/AgQM6fPiwevTo4WgrKCiQJFWqVEmpqamqX79+2RYNAADKNZcelvLw8FBYWJiSk5MdbQUFBUpOTlZERESh/o0bN9bevXuVkpLieNx7773q3LmzUlJSOJ8GAAC4/rBUbGysYmJi1Lp1a7Vt21YzZsxQTk6OBg0aJEkaMGCA6tSpo4SEBHl6eqpZs2ZO46tVqyZJhdoBAMD1yeXhpk+fPjpx4oQmTpyo9PR0tWrVSuvXr3ecZHzkyBG5ubn8inUAAFBB2CzLslxdxLWUlZUlPz8/ZWZmytfXt/QXYLOV/jxxZcrwrcxmdZ2y/oSyTWbjuooVX8Ybdznb1mX6lf62Lc73N7tEAACAUQg3AADAKIQbAABgFMINAAAwCuEGAAAYhXADAACMQrgBAABGIdwAAACjEG4AAIBRCDcAAMAohBsAAGAUwg0AADAK4QYAABiFcAMAAIxCuAEAAEYh3AAAAKMQbgAAgFEINwAAwCiEGwAAYBTCDQAAMArhBgAAGIVwAwAAjEK4AQAARiHcAAAAoxBuAACAUQg3AADAKIQbAABgFMINAAAwCuEGAAAYhXADAACMQrgBAABGIdwAAACjEG4AAIBRCDcAAMAohBsAAGAUwg0AADAK4QYAABiFcAMAAIxCuAEAAEYh3AAAAKMQbgAAgFEINwAAwCiEGwAAYBTCDQAAMArhBgAAGIVwAwAAjEK4AQAARiHcAAAAoxBuAACAUQg3AADAKIQbAABgFMINAAAwCuEGAAAYhXADAACMQrgBAABGIdwAAACjEG4AAIBRCDcAAMAohBsAAGAUwg0AADAK4QYAABiFcAMAAIxCuAEAAEYpF+Fm1qxZCg0Nlaenp8LDw7Vjx47L9p0/f746duyo6tWrq3r16oqMjPzd/gAA4Pri8nCTmJio2NhYxcfHa/fu3WrZsqWioqJ0/PjxIvtv2bJF0dHR2rx5s7Zv366QkBB16dJFx44du8aVAwCA8shmWZblygLCw8PVpk0bzZw5U5JUUFCgkJAQjRgxQuPGjfvD8fn5+apevbpmzpypAQMGFJqem5ur3Nxcx/OsrCyFhIQoMzNTvr6+pbcil9hspT9PXJkyfCuzWV2nrD+hbJPZuK5ixZfxxl3OtnWZfqW/bbOysuTn53dF398u3XOTl5enXbt2KTIy0tHm5uamyMhIbd++/Yrmce7cOV24cEE1atQocnpCQoL8/Pwcj5CQkFKpHQAAlE8uDTcnT55Ufn6+goKCnNqDgoKUnp5+RfMYO3asgoODnQLSr8XFxSkzM9PxOHr06FXXDQAAyq9Kri7gakydOlUrVqzQli1b5OnpWWQfu90uu91+jSsDAACu4tJw4+/vL3d3d2VkZDi1Z2RkqFatWr87dtq0aZo6dao2bdqkFi1alGWZAACgAnHpYSkPDw+FhYUpOTnZ0VZQUKDk5GRFRERcdtxLL72kKVOmaP369WrduvW1KBUAAFQQLj8sFRsbq5iYGLVu3Vpt27bVjBkzlJOTo0GDBkmSBgwYoDp16ighIUGS9OKLL2rixIlavny5QkNDHefm+Pj4yMfHx2XrAQAAygeXh5s+ffroxIkTmjhxotLT09WqVSutX7/ecZLxkSNH5Ob2vx1Mc+bMUV5enh544AGn+cTHx2vSpEnXsnQAAFAOufw+N9daca6TLxFuiOI63OfGSNznxlzc58Zg1/N9bgAAAEob4QYAABiFcAMAAIxCuAEAAEYh3AAAAKMQbgAAgFEINwAAwCiEGwAAYBTCDQAAMArhBgAAGIVwAwAAjEK4AQAARiHcAAAAoxBuAACAUQg3AADAKIQbAABgFMINAAAwCuEGAAAYhXADAACMQrgBAABGIdwAAACjEG4AAIBRCDcAAMAohBsAAGAUwg0AADAK4QYAABiFcAMAAIxCuAEAAEYh3AAAAKMQbgAAgFEINwAAwCiEGwAAYBTCDQAAMArhBgAAGIVwAwAAjEK4AQAARiHcAAAAoxBuAACAUQg3AADAKIQbAABgFMINAAAwCuEGAAAYhXADAACMQrgBAABGIdwAAACjEG4AAIBRCDcAAMAohBsAAGAUwg0AADAK4QYAABiFcAMAAIxCuAEAAEYh3AAAAKMQbgAAgFEINwAAwCiEGwAAYBTCDQAAMArhBgAAGIVwAwAAjEK4AQAARiHcAAAAoxBuAACAUcpFuJk1a5ZCQ0Pl6emp8PBw7dix43f7r1y5Uo0bN5anp6eaN2+udevWXaNKAQBAeefycJOYmKjY2FjFx8dr9+7datmypaKionT8+PEi+2/btk3R0dEaPHiwvvrqK/Xq1Uu9evXS119/fY0rBwAA5ZHNsizLlQWEh4erTZs2mjlzpiSpoKBAISEhGjFihMaNG1eof58+fZSTk6O1a9c62m677Ta1atVKc+fO/cPlZWVlyc/PT5mZmfL19S29FbnEZiv9eeLKlOFbmc3qOmX9CWWbzMZ1FSu+jDfucraty/Qr/W1bnO/vSqW+9GLIy8vTrl27FBcX52hzc3NTZGSktm/fXuSY7du3KzY21qktKipKq1evLrJ/bm6ucnNzHc8zMzMl/fIiwTBsUyOV+WY9X8bzx2WV+efwubKdPX5HGWzbS++XK9kn49Jwc/LkSeXn5ysoKMipPSgoSN99912RY9LT04vsn56eXmT/hIQETZ48uVB7SEhICatGueXn5+oKUAbYrObym8rGNdaQstu22dnZ8vuDDwaXhptrIS4uzmlPT0FBgU6dOqWaNWvKxrEGh6ysLIWEhOjo0aNlc7gOLsO2NRfb1kxs16JZlqXs7GwFBwf/YV+Xhht/f3+5u7srIyPDqT0jI0O1atUqckytWrWK1d9ut8tutzu1VatWreRFG87X15c/JkOxbc3FtjUT27WwP9pjc4lLr5by8PBQWFiYkpOTHW0FBQVKTk5WREREkWMiIiKc+kvSxo0bL9sfAABcX1x+WCo2NlYxMTFq3bq12rZtqxkzZignJ0eDBg2SJA0YMEB16tRRQkKCJOmpp55Sp06d9Morr6h79+5asWKFdu7cqXnz5rlyNQAAQDnh8nDTp08fnThxQhMnTlR6erpatWql9evXO04aPnLkiNzc/reDqV27dlq+fLnGjx+vZ599Vg0bNtTq1avVrFkzV62CEex2u+Lj4wsdwkPFx7Y1F9vWTGzXq+fy+9wAAACUJpffoRgAAKA0EW4AAIBRCDcAAMAohBsAAGAUwo3B/vznP2vUqFGuLgNAGbHZbJf9Xb2r6YuK69fb+fDhw7LZbEpJSXFpTa5AuAGuse3bt8vd3V3du3d3dSkoRQMHDpTNZpPNZpOHh4caNGig559/XhcvXiyzZf7000/q2rVrqfdFyfz6PVC5cmXVq1dPzzzzjM6f59dZrzXCDXCNLViwQCNGjNCnn36q//znPy6rIy8vz2XLNtXdd9+tn376Sfv379eYMWM0adIkvfzyy4X6ldZrX6tWrSu+F0px+qLkLr0HDh48qFdffVVvvvmm4uPjXV3WdYdwc504ffq0BgwYoOrVq8vb21tdu3bV/v37HdN/+OEH9ejRQ9WrV1eVKlXUtGlTrVu3zjH24YcfVkBAgLy8vNSwYUMtWrTIVatSoZ09e1aJiYkaOnSounfvrsWLFztN/+c//6k2bdrI09NT/v7+uu+++xzTcnNzNXbsWIWEhMhut6tBgwZasGCBJGnx4sWFfjNt9erVTj8OO2nSJLVq1Up///vfVa9ePXl6ekqS1q9frw4dOqhatWqqWbOm7rnnHh04cMBpXj/++KOio6NVo0YNValSRa1bt9YXX3yhw4cPy83NTTt37nTqP2PGDNWtW1cFBQVX+5JVKHa7XbVq1VLdunU1dOhQRUZGas2aNRo4cKB69eqlv/3tbwoODlajRo0kSUePHtVDDz2katWqqUaNGurZs6cOHz7sNM+FCxeqadOmstvtql27toYPH+6Y9utDEHl5eRo+fLhq164tT09P1a1b13Fn99/2laS9e/fqjjvukJeXl2rWrKnHH39cZ8+edUy/VPO0adNUu3Zt1axZU8OGDdOFCxdK/4UzyKX3QEhIiHr16qXIyEht3LhR0i8/L5SQkKB69erJy8tLLVu21Hvvvec0/ptvvtE999wjX19fVa1aVR07dnT8PX755Ze666675O/vLz8/P3Xq1Em7d+++5utYERBurhMDBw7Uzp07tWbNGm3fvl2WZalbt26OD6phw4YpNzdXn376qfbu3asXX3xRPj4+kqQJEybo22+/1Ycffqh9+/Zpzpw58vf3d+XqVFjvvvuuGjdurEaNGql///5auHChLt1HMykpSffdd5+6deumr776SsnJyWrbtq1j7IABA/TOO+/o9ddf1759+/Tmm286ttGVSktL06pVq/T+++87jsPn5OQoNjZWO3fuVHJystzc3HTfffc5gsnZs2fVqVMnHTt2TGvWrNGePXv0zDPPqKCgQKGhoYqMjCwUdhctWqSBAwc63V38euTl5eXYS5OcnKzU1FRt3LhRa9eu1YULFxQVFaWqVavqs88+09atW+Xj46O7777bMWbOnDkaNmyYHn/8ce3du1dr1qxRgwYNilzW66+/rjVr1ujdd99Vamqq3n77bYWGhhbZNycnR1FRUapevbq+/PJLrVy5Ups2bXIKTpK0efNmHThwQJs3b9aSJUu0ePHiQoEcl/f1119r27Zt8vDwkCQlJCRo6dKlmjt3rr755huNHj1a/fv31yeffCJJOnbsmG6//XbZ7XZ9/PHH2rVrlx599FHHoc3s7GzFxMTo888/17/+9S81bNhQ3bp1U3Z2tsvWsdyyYKxOnTpZTz31lPX9999bkqytW7c6pp08edLy8vKy3n33XcuyLKt58+bWpEmTipxPjx49rEGDBl2Tmk3Xrl07a8aMGZZlWdaFCxcsf39/a/PmzZZlWVZERIT18MMPFzkuNTXVkmRt3LixyOmLFi2y/Pz8nNo++OAD69d/4vHx8VblypWt48eP/26NJ06csCRZe/futSzLst58802ratWq1s8//1xk/8TERKt69erW+fPnLcuyrF27dlk2m806dOjQ7y7HNDExMVbPnj0ty7KsgoICa+PGjZbdbreefvppKyYmxgoKCrJyc3Md/ZctW2Y1atTIKigocLTl5uZaXl5e1oYNGyzLsqzg4GDrueeeu+wyJVkffPCBZVmWNWLECOuOO+5wmt/l+s6bN8+qXr26dfbsWcf0pKQky83NzUpPT3esT926da2LFy86+jz44INWnz59rvxFuc7ExMRY7u7uVpUqVSy73W5Jstzc3Kz33nvPOn/+vOXt7W1t27bNaczgwYOt6Ohoy7IsKy4uzqpXr56Vl5d3RcvLz8+3qlatav3zn/90tP16Ox86dMiSZH311Velsn4VyfX9z6rrxL59+1SpUiWFh4c72mrWrKlGjRpp3759kqSRI0fqr3/9q9q3b6/4+Hj9+9//dvQdOnSoVqxYoVatWumZZ57Rtm3brvk6mCA1NVU7duxQdHS0JKlSpUrq06eP49BSSkqK7rzzziLHpqSkyN3dXZ06dbqqGurWrauAgACntv379ys6Olo33XSTfH19Hf/aP3LkiGPZt9xyi2rUqFHkPHv16iV3d3d98MEHkn45RNa5c+fL7jUw2dq1a+Xj4yNPT0917dpVffr00aRJkyRJzZs3d/wLXpL27NmjtLQ0Va1aVT4+PvLx8VGNGjV0/vx5HThwQMePH9d//vOfy74nfmvgwIFKSUlRo0aNNHLkSH300UeX7btv3z61bNlSVapUcbS1b99eBQUFSk1NdbQ1bdpU7u7ujue1a9fW8ePHr/TluC517txZKSkp+uKLLxQTE6NBgwapd+/eSktL07lz53TXXXc5trePj4+WLl3qOOyUkpKijh07qnLlykXOOyMjQ0OGDFHDhg3l5+cnX19fnT171vG3iv9x+Q9nonx47LHHFBUVpaSkJH300UdKSEjQK6+8ohEjRqhr16764YcftG7dOm3cuFF33nmnhg0bpmnTprm67AplwYIFunjxooKDgx1tlmXJbrdr5syZ8vLyuuzY35smSW5ubo7DW5cUdW7Er7/MLunRo4fq1q2r+fPnKzg4WAUFBWrWrJnj0MgfLdvDw0MDBgzQokWLdP/992v58uV67bXXfneMqTp37qw5c+bIw8NDwcHBqlTpfx+xv33tz549q7CwML399tuF5hMQEFDsQ3q33nqrDh06pA8//FCbNm3SQw89pMjIyELndBTHb79kbTbbdXceVXFVqVLFcehw4cKFatmypRYsWOD4ceekpCTVqVPHacylE73/6G8tJiZGP//8s1577TXVrVtXdrtdERERXBxQBPbcXAeaNGmiixcv6osvvnC0/fzzz0pNTdXNN9/saAsJCdGTTz6p999/X2PGjNH8+fMd0wICAhQTE6O33npLM2bM0Lx5867pOlR0Fy9e1NKlS/XKK68oJSXF8dizZ4+Cg4P1zjvvqEWLFkpOTi5yfPPmzVVQUOA4Nv9bAQEBys7OVk5OjqPtSu5tcel9MH78eN15551q0qSJTp8+7dSnRYsWSklJ0alTpy47n8cee0ybNm3S7NmzdfHiRd1///1/uGwTXfpiu/HGG52CTVFuvfVW7d+/X4GBgWrQoIHTw8/PT1WrVlVoaOhl3xNF8fX1VZ8+fTR//nwlJiZq1apVRW63Jk2aaM+ePU7vl61bt8rNzc1xsjOunpubm5599lmNHz9eN998s+x2u44cOVJoe4eEhEj65W/ts88+u+xJ21u3btXIkSPVrVs3x0nmJ0+evJarVGEQbq4DDRs2VM+ePTVkyBB9/vnn2rNnj/r37686deqoZ8+ekqRRo0Zpw4YNOnTokHbv3q3NmzerSZMmkqSJEyfqH//4h9LS0vTNN99o7dq1jmm4MmvXrtXp06c1ePBgNWvWzOnRu3dvLViwQPHx8XrnnXcUHx+vffv2OU7slqTQ0FDFxMTo0Ucf1erVq3Xo0CFt2bJF7777riQpPDxc3t7eevbZZ3XgwAEtX778ik78rF69umrWrKl58+YpLS1NH3/8sWJjY536REdHq1atWurVq5e2bt2qgwcPatWqVdq+fbujT5MmTXTbbbdp7Nixio6O/sN/gUJ6+OGH5e/vr549e+qzzz5zbNORI0fqxx9/lPTLFW6vvPKKXn/9de3fv1+7d+/WG2+8UeT8pk+frnfeeUffffedvv/+e61cuVK1atUqdBXdpWV7enoqJiZGX3/9tTZv3qwRI0bokUceUVBQUFmu9nXnwQcflLu7u9588009/fTTGj16tJYsWaIDBw44tueSJUskScOHD1dWVpb69u2rnTt3av/+/Vq2bJnjUGHDhg21bNky7du3T1988YUefvhh/tYug3BznVi0aJHCwsJ0zz33KCIiQpZlad26dY7dzvn5+Ro2bJiaNGmiu+++W3/60580e/ZsSb8cdoiLi1OLFi10++23y93dXStWrHDl6lQ4CxYsUGRkpPz8/ApN6927t3bu3KkaNWpo5cqVWrNmjVq1aqU77rhDO3bscPSbM2eOHnjgAf3lL39R48aNNWTIEMe/vGvUqKG33npL69atU/PmzfXOO+84zvX4PW5ublqxYoV27dqlZs2aafTo0YXuy+Lh4aGPPvpIgYGB6tatm5o3b66pU6c6nYshSYMHD1ZeXp4effTRErxC1x9vb299+umnuvHGG3X//ferSZMmGjx4sM6fPy9fX19JvxyGmDFjhmbPnq2mTZvqnnvucbqFw69VrVpVL730klq3bq02bdro8OHDWrduXZGHt7y9vbVhwwadOnVKbdq00QMPPKA777xTM2fOLNN1vh5VqlRJw4cP10svvaS4uDhNmDBBCQkJjs/apKQk1atXT9Iv50J+/PHHjisUw8LCNH/+fMfn9IIFC3T69GndeuuteuSRRzRy5EgFBga6cvXKLZv12wP1AFACU6ZM0cqVK51ORgcAV2DPDYCrcvbsWX399deaOXOmRowY4epyAIBwA+DqDB8+XGFhYfrzn//MISkA5QKHpQAAgFHYcwMAAIxCuAEAAEYh3AAAAKMQbgAAgFEINwAAwCiEGwAAYBTCDQAAMArhBgAAGOX/AU4+GDW1k3WPAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting accuracy, precision, and recall\n",
    "x = ['loss','Accuracy', 'Precision', 'Recall']\n",
    "y = [loss,accuracy, precision, recall]\n",
    "colors = ['red','blue', 'green', 'orange'] \n",
    "plt.bar(x, y,color=colors)\n",
    "plt.ylim(0, 1.0)\n",
    "plt.ylabel('Score')\n",
    "plt.title('Model Performance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 127, 127, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 62, 62, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 246016)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               31490176  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,509,697\n",
      "Trainable params: 31,509,697\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.save(\"splicing_detect.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 164ms/step\n",
      "The image is likely authentic.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "# Load the model\n",
    "model = load_model('splicing_detect.h5')\n",
    "\n",
    "# Load and preprocess the image\n",
    "img_path = 'testing_set/original/canonxt_29_sub_08.png'\n",
    "image_size = (256, 256)\n",
    "img = image.load_img(img_path, target_size=image_size)\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = img_array / 255.0  # Normalize the image\n",
    "\n",
    "# Expand the dimensions to match the input shape of the model\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(img_array)\n",
    "probability_spliced = predictions[0][0]\n",
    "threshold = 0.6 # Adjust the threshold as needed\n",
    "\n",
    "if probability_spliced >= threshold:\n",
    "    print(\"The image is likely spliced.\")\n",
    "else:\n",
    "    print(\"The image is likely authentic.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 283ms/step\n",
      "The image is likely spliced.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Function to analyze the image and mark merged regions\n",
    "def mark_merged_regions(image_path, model, threshold=0.6):\n",
    "    # Load and preprocess the image\n",
    "    image_size = (256, 256)\n",
    "    img = image.load_img(image_path, target_size=image_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = img_array / 255.0  # Normalize the image\n",
    "\n",
    "    # Expand the dimensions to match the input shape of the model\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(img_array)\n",
    "    probability_spliced = predictions[0][0]\n",
    "\n",
    "    if probability_spliced >= threshold:\n",
    "        print(\"The image is likely spliced.\")\n",
    "\n",
    "        # Load the image using OpenCV for visualization\n",
    "        img_cv = cv2.imread(image_path)\n",
    "\n",
    "        # Convert the image to grayscale\n",
    "        img_gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Apply adaptive thresholding to obtain a binary mask of potential merged regions\n",
    "        _, img_thresh = cv2.threshold(img_gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "        # Find contours of the potential merged regions\n",
    "        contours, _ = cv2.findContours(img_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Iterate over the contours and mark the merged regions\n",
    "        for contour in contours:\n",
    "            # Calculate the contour area\n",
    "            area = cv2.contourArea(contour)\n",
    "\n",
    "            # If the area is above a certain threshold, consider it a merged region\n",
    "            if area > 100:\n",
    "                # Draw a filled contour to mark the merged region\n",
    "                cv2.drawContours(img_cv, [contour], -1, (0, 0, 255), cv2.FILLED)\n",
    "\n",
    "        # Display the output image with marked merged regions\n",
    "        cv2.imshow('Output Image', img_cv)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    else:\n",
    "        print(\"The image is likely authentic.\")\n",
    "\n",
    "# Load the model\n",
    "model = load_model('splicing_detect.h5')\n",
    "\n",
    "# Analyze the image and mark merged regions\n",
    "img_path = 'testing_set/spliced/spliced1.png'\n",
    "mark_merged_regions(img_path, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step\n",
      "<class 'numpy.ndarray'>\n",
      "['T', '__abs__', '__add__', '__and__', '__array__', '__array_finalize__', '__array_function__', '__array_interface__', '__array_prepare__', '__array_priority__', '__array_struct__', '__array_ufunc__', '__array_wrap__', '__bool__', '__class__', '__class_getitem__', '__complex__', '__contains__', '__copy__', '__deepcopy__', '__delattr__', '__delitem__', '__dir__', '__divmod__', '__dlpack__', '__dlpack_device__', '__doc__', '__eq__', '__float__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__iadd__', '__iand__', '__ifloordiv__', '__ilshift__', '__imatmul__', '__imod__', '__imul__', '__index__', '__init__', '__init_subclass__', '__int__', '__invert__', '__ior__', '__ipow__', '__irshift__', '__isub__', '__iter__', '__itruediv__', '__ixor__', '__le__', '__len__', '__lshift__', '__lt__', '__matmul__', '__mod__', '__mul__', '__ne__', '__neg__', '__new__', '__or__', '__pos__', '__pow__', '__radd__', '__rand__', '__rdivmod__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rlshift__', '__rmatmul__', '__rmod__', '__rmul__', '__ror__', '__rpow__', '__rrshift__', '__rshift__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__setitem__', '__setstate__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__xor__', 'all', 'any', 'argmax', 'argmin', 'argpartition', 'argsort', 'astype', 'base', 'byteswap', 'choose', 'clip', 'compress', 'conj', 'conjugate', 'copy', 'ctypes', 'cumprod', 'cumsum', 'data', 'diagonal', 'dot', 'dtype', 'dump', 'dumps', 'fill', 'flags', 'flat', 'flatten', 'getfield', 'imag', 'item', 'itemset', 'itemsize', 'max', 'mean', 'min', 'nbytes', 'ndim', 'newbyteorder', 'nonzero', 'partition', 'prod', 'ptp', 'put', 'ravel', 'real', 'repeat', 'reshape', 'resize', 'round', 'searchsorted', 'setfield', 'setflags', 'shape', 'size', 'sort', 'squeeze', 'std', 'strides', 'sum', 'swapaxes', 'take', 'tobytes', 'tofile', 'tolist', 'tostring', 'trace', 'transpose', 'var', 'view']\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(img_array)\n",
    "\n",
    "print(type(predictions))\n",
    "print(dir(predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
